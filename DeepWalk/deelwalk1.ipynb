{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_list=[[1,6], [0,2], [1,3], [2, 4], [3, 5], [4,6], [5,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=3 #window size\n",
    "d=2 #embedding size\n",
    "y=2 #walks per vertex\n",
    "t=6 #walk length\n",
    "size_vertex=7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=[0,1,2,3,4,5,6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi=torch.rand((size_vertex, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomWalk(v,t):\n",
    "    walk=[v]\n",
    "#     print(\"v= \",v)\n",
    "#     print(\"walk= \",walk)\n",
    "    for i in range(t-1):\n",
    "        v=adj_list[v][random.randint(0,1)]\n",
    "        walk.append(v)\n",
    "#         print(\"v= \",v)\n",
    "#         print(\"walk= \",walk)\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 4, 3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomWalk(2,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def SkipGram(wvi,  w):\n",
    "#     for j in range(len(wvi)):\n",
    "#         for k in range(max(0,j-w) , min(j+w, len(wvi)):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(y):\n",
    "#     random.shuffle(v)\n",
    "#     for vi in v:\n",
    "#         wvi=RandomWalk(vi,t)\n",
    "#         SkipGram(wvi, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip gram model is defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_create(wvi,  w):\n",
    "    idx_pairs = []\n",
    "    for center_node_pos in range(len(wvi)):\n",
    "        for i in range(-w,w+1):\n",
    "            context_node_pos=center_node_pos+i\n",
    "#             print(\"cont_node_pos ____befo= \",context_node_pos)\n",
    "            if context_node_pos<0 or context_node_pos>=len(wvi) or context_node_pos==center_node_pos:\n",
    "                continue\n",
    "            #context_word_idx = indices[context_word_pos]\n",
    "#             print(\"cont_node_pos= \",context_node_pos)\n",
    "            idx_pairs.append((wvi[center_node_pos], wvi[context_node_pos]))\n",
    "#         print(\"===================================\")\n",
    "#         print(idx_pairs)\n",
    "\n",
    "#     idx_pairs = np.array(idx_pairs)\n",
    "    return idx_pairs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pair_create(RandomWalk(2,t),w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_pairs=[]\n",
    "for i in range(len(v)):\n",
    "    for j in range(y):\n",
    "        idx_pairs.append(pair_create(RandomWalk(i,t),w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(336, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_pairs=np.array([np.array(i) for i in idx_pairs])\n",
    "idx_pairs=idx_pairs.reshape(-1,2)\n",
    "idx_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_layer(node_idx):\n",
    "    x = torch.zeros(len(v)).float()\n",
    "    x[node_idx] = 1.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shubham/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epo 0: 3.1456782817840576\n",
      "Loss at epo 10: 2.183809280395508\n",
      "Loss at epo 20: 1.9378072023391724\n",
      "Loss at epo 30: 1.831724762916565\n",
      "Loss at epo 40: 1.7757853269577026\n",
      "Loss at epo 50: 1.7429765462875366\n",
      "Loss at epo 60: 1.7220067977905273\n",
      "Loss at epo 70: 1.7074934244155884\n",
      "Loss at epo 80: 1.6967012882232666\n",
      "Loss at epo 90: 1.688170313835144\n"
     ]
    }
   ],
   "source": [
    "embedding_dims = 5\n",
    "W1 = Variable(torch.randn(embedding_dims, len(v)).float(), requires_grad=True)\n",
    "W2 = Variable(torch.randn(len(v), embedding_dims).float(), requires_grad=True)\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epo in range(num_epochs):\n",
    "    loss_val = 0\n",
    "    for data, target in idx_pairs:\n",
    "        x = Variable(get_input_layer(data)).float()\n",
    "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
    "\n",
    "        z1 = torch.matmul(W1, x)\n",
    "        z2 = torch.matmul(W2, z1)\n",
    "    \n",
    "        log_softmax = F.log_softmax(z2, dim=0)\n",
    "\n",
    "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
    "        loss_val += loss.data[0]\n",
    "        loss.backward()\n",
    "        W1.data -= learning_rate * W1.grad.data\n",
    "        W2.data -= learning_rate * W2.grad.data\n",
    "\n",
    "        W1.grad.data.zero_()\n",
    "        W2.grad.data.zero_()\n",
    "    if epo % 10 == 0:    \n",
    "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4268, -0.7080, -0.2460, -0.0298,  0.5165,  0.0486, -0.2550],\n",
       "         [ 0.4321, -1.6612, -1.1200,  0.4259, -0.2870,  0.7627, -0.6278],\n",
       "         [ 0.8007,  0.4945,  0.5461,  0.0590, -0.2820,  0.8470, -0.0704],\n",
       "         [-0.4764,  0.0360, -1.1690,  0.8348, -0.3476,  0.6047,  0.4120],\n",
       "         [ 0.1563,  1.0724,  0.9587,  0.3117,  0.3879,  1.6632, -0.8993]]),\n",
       " tensor([[-0.2597, -1.4178,  0.0346,  0.1491, -0.9558],\n",
       "         [-1.1522, -0.6324,  0.8297, -0.6346, -0.9648],\n",
       "         [-1.0262, -0.9026, -0.3238,  0.3878, -0.0274],\n",
       "         [ 0.2300, -0.5019, -1.7414, -0.5677,  0.8247],\n",
       "         [ 1.2475, -0.5316,  0.2394,  0.9477, -0.2287],\n",
       "         [ 2.1535, -0.7676,  0.1213,  0.7389, -0.7456],\n",
       "         [-2.5345,  0.2554, -0.5300, -0.2536, -0.1836]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1,W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
